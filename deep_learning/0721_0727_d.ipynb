{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0721-0727_d.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM3mgVCDwDtPGFsgzPEmhPP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanbitgoun/GJ_AI/blob/main/deep_learning/0721_0727_d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJxD3AqHjtAS"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIZ75OZVkRX0",
        "outputId": "19abe751-4686-4214-8f4f-8c6355ce48d0"
      },
      "source": [
        "df = pd.read_csv('/content/abalone_mini.csv')\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4 entries, 0 to 3\n",
            "Data columns (total 9 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   M       4 non-null      object \n",
            " 1   0.455   4 non-null      float64\n",
            " 2   0.365   4 non-null      float64\n",
            " 3   0.095   4 non-null      float64\n",
            " 4   0.514   4 non-null      float64\n",
            " 5   0.2245  4 non-null      float64\n",
            " 6   0.101   4 non-null      float64\n",
            " 7   0.15    4 non-null      float64\n",
            " 8   15      4 non-null      int64  \n",
            "dtypes: float64(7), int64(1), object(1)\n",
            "memory usage: 416.0+ bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Zd2Kek2x7tt",
        "outputId": "434c458a-199d-4b46-a143-a333c3f3f392"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QniVnExClWK3"
      },
      "source": [
        "데이터 불러오기\n",
        "\n",
        "데이터 분할하기 \n",
        "\n",
        "파라미터 생성하기 \n",
        "\n",
        "신경망 연산하기 \n",
        "\n",
        "역전파 연산하기 \n",
        "\n",
        "성능 확인하기 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxJMtrlnkXxA"
      },
      "source": [
        "def main_execute(epoch_count = 10, mb_size = 2, report = 2, train_ratio = 0.8):\n",
        "  load_dataset()\n",
        "  weight_initial, bias_initial = init_param()\n",
        "  losses_mean_row, accs_mean_row, final_acc = train_and_test(epoch_count, mb_size, report, train_ratio)\n",
        "  \n",
        "  return weight_initial, bias_initial, losses_mean_row, accs_mean_row, final_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhZb4Z0QnuKl"
      },
      "source": [
        "# 데이터 로드 & 원핫벡터 처리\n",
        "def load_dataset():\n",
        "  with open('/content/abalone.csv' ) as csvfile:\n",
        "    csvreader = csv.reader(csvfile)\n",
        "    next(csvreader)\n",
        "    rows = []  \n",
        "    for row in csvreader:\n",
        "      rows.append(row)\n",
        "  \n",
        "  global data, input_cnt, output_cnt\n",
        "  \n",
        "  input_cnt, output_cnt = 10, 1\n",
        "  data = np.zeros( [len(rows),input_cnt + output_cnt] )\n",
        "\n",
        "  for n, row in enumerate(rows):\n",
        "    if row[0] == 'M': data[n, 0] = 1\n",
        "    if row[0] == 'F': data[n, 1] = 1\n",
        "    if row[0] == 'I': data[n, 2] = 1\n",
        "    data[n, 3:] = row[1:]  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4kgU1owq1mi"
      },
      "source": [
        "%run /content/MathUtils.ipynb\n",
        "load_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZUsRYoDrtnl",
        "outputId": "6099b01c-f78b-4579-b4d0-ab6e35b81f05"
      },
      "source": [
        "print(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.      0.      0.     ...  0.101   0.15   15.    ]\n",
            " [ 1.      0.      0.     ...  0.0485  0.07    7.    ]\n",
            " [ 0.      1.      0.     ...  0.1415  0.21    9.    ]\n",
            " ...\n",
            " [ 1.      0.      0.     ...  0.2875  0.308   9.    ]\n",
            " [ 0.      1.      0.     ...  0.261   0.296  10.    ]\n",
            " [ 1.      0.      0.     ...  0.3765  0.495  12.    ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwEf9OGzrvBI"
      },
      "source": [
        "# 가중치와 편향 설정\n",
        "def init_param():\n",
        "  global weight, bias\n",
        "\n",
        "  weight_initial = []\n",
        "  bias_initial = []\n",
        "  weight = np.random.normal(RND_MEAN, RND_STD, size=[input_cnt, output_cnt])\n",
        "  bias = np.zeros([output_cnt]) # np.zeros 쓰는 이유 : bias 값에 많은영향 따라서 초기값 0으로 설정\n",
        "  print('initial Weight Value : \\n{} '.format(weight))\n",
        "  print('Initial Bias Value : \\n{} '.format(bias))\n",
        "\n",
        "  weight_initial.append(weight)\n",
        "  bias_initial.append(bias)\n",
        "\n",
        "  return weight_initial, bias_initial"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SYtZp3HtJSK",
        "outputId": "f24de4dc-6e0c-4598-cf2b-3b7aba2d4cf3"
      },
      "source": [
        "weight_initial, bias_initial = init_param()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial Weight Value : \n",
            "[[-0.04572553]\n",
            " [-0.02540183]\n",
            " [ 0.04501336]\n",
            " [ 0.02834907]\n",
            " [-0.02457969]\n",
            " [ 0.03824517]\n",
            " [-0.00993385]\n",
            " [-0.05345577]\n",
            " [ 0.03465681]\n",
            " [ 0.00118109]] \n",
            "Initial Bias Value : \n",
            "[0.] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdQQyyoHtR02"
      },
      "source": [
        "def train_and_test():\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaCEqpAtt_-1"
      },
      "source": [
        "# 데이터 셔플, mini_batch_step_count & test_idx 반환\n",
        "def arrange_data(mb_size, train_ratio):\n",
        "  global shuffle_map, test_begin_index\n",
        "\n",
        "  shuffle_map = np.arange(data.shape[0])\n",
        "  np.random.shuffle(shuffle_map)\n",
        "\n",
        "  mini_batch_step_count = int(data.shape[0] * train_ratio) // mb_size\n",
        "  test_begin_index = mini_batch_step_count * mb_size\n",
        "\n",
        "  return mini_batch_step_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd4Gsw_pywKt"
      },
      "source": [
        "mini_batch_step_count = arrange_data(mb_size = 2, train_ratio = 0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tjnEqKo0A-8",
        "outputId": "69e02322-9787-4bf9-fa2a-1727110bdd71"
      },
      "source": [
        "print(\"mini_batch_step_count :\", mini_batch_step_count)\n",
        "print(\"shuffle_map :\", shuffle_map[:3])\n",
        "print(\"test_begin_index : \", test_begin_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mini_batch_step_count : 1670\n",
            "shuffle_map : [2630 3675 3669]\n",
            "test_begin_index :  3340\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd1HY_Kl0BT-"
      },
      "source": [
        "def get_test_data():\n",
        "  # shuffle된 index로 test_data 분할\n",
        "  test_data = data[shuffle_map[ test_begin_index: ] ] \n",
        "  return test_data[:, :-output_cnt], test_data[:, -output_cnt:]                 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsiULTGP0gDg",
        "outputId": "842df7a3-6f6b-498b-c96a-6e730c7cfa1e"
      },
      "source": [
        "test_x, test_y = get_test_data()\n",
        "print(test_x)\n",
        "print(\"============================\")\n",
        "print(test_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.     1.     0.     ... 0.186  0.11   0.145 ]\n",
            " [0.     1.     0.     ... 0.3005 0.131  0.15  ]\n",
            " [0.     1.     0.     ... 0.281  0.117  0.1335]\n",
            " ...\n",
            " [0.     1.     0.     ... 0.1945 0.103  0.155 ]\n",
            " [0.     1.     0.     ... 0.643  0.2465 0.416 ]\n",
            " [1.     0.     0.     ... 0.4375 0.196  0.325 ]]\n",
            "============================\n",
            "[[10.]\n",
            " [ 6.]\n",
            " [ 7.]\n",
            " [11.]\n",
            " [15.]\n",
            " [12.]\n",
            " [11.]\n",
            " [10.]\n",
            " [ 8.]\n",
            " [ 3.]\n",
            " [15.]\n",
            " [13.]\n",
            " [ 6.]\n",
            " [10.]\n",
            " [14.]\n",
            " [ 8.]\n",
            " [13.]\n",
            " [13.]\n",
            " [ 8.]\n",
            " [ 8.]\n",
            " [ 9.]\n",
            " [15.]\n",
            " [11.]\n",
            " [ 9.]\n",
            " [11.]\n",
            " [ 7.]\n",
            " [12.]\n",
            " [10.]\n",
            " [13.]\n",
            " [ 9.]\n",
            " [ 7.]\n",
            " [13.]\n",
            " [ 7.]\n",
            " [ 7.]\n",
            " [ 9.]\n",
            " [ 6.]\n",
            " [11.]\n",
            " [12.]\n",
            " [10.]\n",
            " [10.]\n",
            " [10.]\n",
            " [ 9.]\n",
            " [ 7.]\n",
            " [ 8.]\n",
            " [ 7.]\n",
            " [ 6.]\n",
            " [14.]\n",
            " [ 8.]\n",
            " [ 7.]\n",
            " [ 8.]\n",
            " [ 9.]\n",
            " [16.]\n",
            " [ 7.]\n",
            " [ 8.]\n",
            " [10.]\n",
            " [ 5.]\n",
            " [11.]\n",
            " [11.]\n",
            " [ 7.]\n",
            " [20.]\n",
            " [ 8.]\n",
            " [ 6.]\n",
            " [11.]\n",
            " [10.]\n",
            " [ 8.]\n",
            " [13.]\n",
            " [21.]\n",
            " [11.]\n",
            " [ 9.]\n",
            " [ 8.]\n",
            " [ 8.]\n",
            " [ 8.]\n",
            " [22.]\n",
            " [13.]\n",
            " [13.]\n",
            " [12.]\n",
            " [ 7.]\n",
            " [10.]\n",
            " [ 8.]\n",
            " [10.]\n",
            " [ 6.]\n",
            " [ 7.]\n",
            " [ 8.]\n",
            " [13.]\n",
            " [12.]\n",
            " [12.]\n",
            " [11.]\n",
            " [12.]\n",
            " [14.]\n",
            " [11.]\n",
            " [ 9.]\n",
            " [ 8.]\n",
            " [10.]\n",
            " [17.]\n",
            " [20.]\n",
            " [14.]\n",
            " [ 8.]\n",
            " [ 8.]\n",
            " [ 4.]\n",
            " [11.]\n",
            " [11.]\n",
            " [14.]\n",
            " [11.]\n",
            " [ 7.]\n",
            " [ 8.]\n",
            " [ 9.]\n",
            " [11.]\n",
            " [14.]\n",
            " [10.]\n",
            " [11.]\n",
            " [ 9.]\n",
            " [ 9.]\n",
            " [10.]\n",
            " [11.]\n",
            " [11.]\n",
            " [ 7.]\n",
            " [11.]\n",
            " [ 9.]\n",
            " [15.]\n",
            " [ 8.]\n",
            " [10.]\n",
            " [ 9.]\n",
            " [11.]\n",
            " [12.]\n",
            " [11.]\n",
            " [15.]\n",
            " [13.]\n",
            " [ 9.]\n",
            " [ 9.]\n",
            " [13.]\n",
            " [11.]\n",
            " [23.]\n",
            " [ 8.]\n",
            " [ 8.]\n",
            " [ 9.]\n",
            " [10.]\n",
            " [11.]\n",
            " [ 9.]\n",
            " [10.]\n",
            " [ 7.]\n",
            " [ 8.]\n",
            " [10.]\n",
            " [10.]\n",
            " [18.]\n",
            " [11.]\n",
            " [10.]\n",
            " [ 7.]\n",
            " [ 6.]\n",
            " [17.]\n",
            " [12.]\n",
            " [ 8.]\n",
            " [ 6.]\n",
            " [17.]\n",
            " [ 9.]\n",
            " [ 8.]\n",
            " [10.]\n",
            " [11.]\n",
            " [11.]\n",
            " [ 4.]\n",
            " [11.]\n",
            " [ 5.]\n",
            " [ 5.]\n",
            " [ 7.]\n",
            " [ 7.]\n",
            " [11.]\n",
            " [11.]\n",
            " [ 7.]\n",
            " [ 9.]\n",
            " [ 7.]\n",
            " [10.]\n",
            " [ 8.]\n",
            " [ 5.]\n",
            " [10.]\n",
            " [ 9.]\n",
            " [ 7.]\n",
            " [11.]\n",
            " [12.]\n",
            " [10.]\n",
            " [10.]\n",
            " [ 7.]\n",
            " [ 6.]\n",
            " [19.]\n",
            " [17.]\n",
            " [ 6.]\n",
            " [ 6.]\n",
            " [10.]\n",
            " [10.]\n",
            " [11.]\n",
            " [ 5.]\n",
            " [10.]\n",
            " [ 6.]\n",
            " [10.]\n",
            " [10.]\n",
            " [12.]\n",
            " [10.]\n",
            " [ 9.]\n",
            " [ 7.]\n",
            " [ 9.]\n",
            " [12.]\n",
            " [ 7.]\n",
            " [10.]\n",
            " [11.]\n",
            " [10.]\n",
            " [10.]\n",
            " [11.]\n",
            " [ 7.]\n",
            " [10.]\n",
            " [ 6.]\n",
            " [11.]\n",
            " [ 9.]\n",
            " [ 9.]\n",
            " [ 5.]\n",
            " [10.]\n",
            " [12.]\n",
            " [12.]\n",
            " [ 8.]\n",
            " [10.]\n",
            " [12.]\n",
            " [ 9.]\n",
            " [ 9.]\n",
            " [ 8.]\n",
            " [10.]\n",
            " [15.]\n",
            " [ 8.]\n",
            " [ 9.]\n",
            " [10.]\n",
            " [ 6.]\n",
            " [15.]\n",
            " [ 7.]\n",
            " [ 8.]\n",
            " [10.]\n",
            " [ 9.]\n",
            " [12.]\n",
            " [ 7.]\n",
            " [ 5.]\n",
            " [12.]\n",
            " [ 9.]\n",
            " [13.]\n",
            " [ 6.]\n",
            " [ 8.]\n",
            " [11.]\n",
            " [ 9.]\n",
            " [10.]\n",
            " [14.]\n",
            " [10.]\n",
            " [ 7.]\n",
            " [ 8.]\n",
            " [ 9.]\n",
            " [17.]\n",
            " [ 7.]\n",
            " [ 9.]\n",
            " [11.]\n",
            " [19.]\n",
            " [10.]\n",
            " [ 8.]\n",
            " [10.]\n",
            " [ 7.]\n",
            " [11.]\n",
            " [13.]\n",
            " [10.]\n",
            " [10.]\n",
            " [ 8.]\n",
            " [13.]\n",
            " [ 9.]\n",
            " [11.]\n",
            " [ 7.]\n",
            " [ 7.]\n",
            " [ 6.]\n",
            " [ 9.]\n",
            " [ 9.]\n",
            " [15.]\n",
            " [ 8.]\n",
            " [ 9.]\n",
            " [ 7.]\n",
            " [ 5.]\n",
            " [ 6.]\n",
            " [15.]\n",
            " [ 9.]\n",
            " [ 6.]\n",
            " [12.]\n",
            " [14.]\n",
            " [ 9.]\n",
            " [ 9.]\n",
            " [ 9.]\n",
            " [ 3.]\n",
            " [ 7.]\n",
            " [10.]\n",
            " [11.]\n",
            " [20.]\n",
            " [11.]\n",
            " [10.]\n",
            " [10.]\n",
            " [20.]\n",
            " [13.]\n",
            " [ 8.]\n",
            " [10.]\n",
            " [14.]\n",
            " [ 7.]\n",
            " [20.]\n",
            " [11.]\n",
            " [13.]\n",
            " [ 8.]\n",
            " [10.]\n",
            " [11.]\n",
            " [ 9.]\n",
            " [ 8.]\n",
            " [ 8.]\n",
            " [ 7.]\n",
            " [ 9.]\n",
            " [ 9.]\n",
            " [12.]\n",
            " [ 6.]\n",
            " [12.]\n",
            " [ 5.]\n",
            " [13.]\n",
            " [10.]\n",
            " [11.]\n",
            " [10.]\n",
            " [12.]\n",
            " [ 6.]\n",
            " [10.]\n",
            " [10.]\n",
            " [ 9.]\n",
            " [ 4.]\n",
            " [ 8.]\n",
            " [ 7.]\n",
            " [11.]\n",
            " [ 8.]\n",
            " [12.]\n",
            " [12.]\n",
            " [11.]\n",
            " [ 6.]\n",
            " [ 7.]\n",
            " [ 6.]\n",
            " [ 9.]\n",
            " [11.]\n",
            " [12.]\n",
            " [ 7.]\n",
            " [10.]\n",
            " [11.]\n",
            " [17.]\n",
            " [ 8.]\n",
            " [10.]\n",
            " [10.]\n",
            " [ 8.]\n",
            " [ 8.]\n",
            " [11.]\n",
            " [10.]\n",
            " [12.]\n",
            " [12.]\n",
            " [10.]\n",
            " [11.]\n",
            " [ 9.]\n",
            " [ 7.]\n",
            " [11.]\n",
            " [14.]\n",
            " [ 9.]\n",
            " [12.]\n",
            " [13.]\n",
            " [ 9.]\n",
            " [ 7.]\n",
            " [10.]\n",
            " [ 6.]\n",
            " [10.]\n",
            " [14.]\n",
            " [21.]\n",
            " [ 9.]\n",
            " [11.]\n",
            " [ 9.]\n",
            " [ 8.]\n",
            " [10.]\n",
            " [ 9.]\n",
            " [ 7.]\n",
            " [ 5.]\n",
            " [10.]\n",
            " [ 9.]\n",
            " [10.]\n",
            " [11.]\n",
            " [12.]\n",
            " [10.]\n",
            " [ 8.]\n",
            " [ 7.]\n",
            " [11.]\n",
            " [ 8.]\n",
            " [ 8.]\n",
            " [ 8.]\n",
            " [ 8.]\n",
            " [14.]\n",
            " [12.]\n",
            " [ 7.]\n",
            " [ 9.]\n",
            " [10.]\n",
            " [13.]\n",
            " [19.]\n",
            " [16.]\n",
            " [ 5.]\n",
            " [16.]\n",
            " [ 9.]\n",
            " [10.]\n",
            " [11.]\n",
            " [ 6.]\n",
            " [11.]\n",
            " [ 6.]\n",
            " [ 4.]\n",
            " [ 6.]\n",
            " [ 7.]\n",
            " [10.]\n",
            " [ 8.]\n",
            " [15.]\n",
            " [ 5.]\n",
            " [ 9.]\n",
            " [ 7.]\n",
            " [ 5.]\n",
            " [ 7.]\n",
            " [10.]\n",
            " [15.]\n",
            " [11.]\n",
            " [ 7.]\n",
            " [ 9.]\n",
            " [ 8.]\n",
            " [12.]\n",
            " [ 7.]\n",
            " [ 6.]\n",
            " [19.]\n",
            " [ 9.]\n",
            " [ 9.]\n",
            " [11.]\n",
            " [ 9.]\n",
            " [10.]\n",
            " [ 6.]\n",
            " [11.]\n",
            " [22.]\n",
            " [10.]\n",
            " [11.]\n",
            " [ 9.]\n",
            " [ 4.]\n",
            " [ 8.]\n",
            " [ 7.]\n",
            " [12.]\n",
            " [ 9.]\n",
            " [ 9.]\n",
            " [10.]\n",
            " [11.]\n",
            " [ 6.]\n",
            " [10.]\n",
            " [ 9.]\n",
            " [12.]\n",
            " [ 7.]\n",
            " [11.]\n",
            " [ 6.]\n",
            " [ 7.]\n",
            " [10.]\n",
            " [ 9.]\n",
            " [ 8.]\n",
            " [10.]\n",
            " [10.]\n",
            " [ 9.]\n",
            " [10.]\n",
            " [20.]\n",
            " [12.]\n",
            " [ 9.]\n",
            " [11.]\n",
            " [17.]\n",
            " [ 4.]\n",
            " [ 6.]\n",
            " [ 7.]\n",
            " [ 9.]\n",
            " [ 8.]\n",
            " [ 6.]\n",
            " [13.]\n",
            " [ 6.]\n",
            " [12.]\n",
            " [13.]\n",
            " [18.]\n",
            " [ 9.]\n",
            " [10.]\n",
            " [10.]\n",
            " [11.]\n",
            " [18.]\n",
            " [ 8.]\n",
            " [ 9.]\n",
            " [10.]\n",
            " [ 8.]\n",
            " [10.]\n",
            " [ 9.]\n",
            " [10.]\n",
            " [ 9.]\n",
            " [ 7.]\n",
            " [12.]\n",
            " [ 8.]\n",
            " [22.]\n",
            " [ 7.]\n",
            " [ 8.]\n",
            " [ 9.]\n",
            " [14.]\n",
            " [ 6.]\n",
            " [11.]\n",
            " [ 7.]\n",
            " [11.]\n",
            " [ 8.]\n",
            " [27.]\n",
            " [10.]\n",
            " [ 9.]\n",
            " [11.]\n",
            " [ 7.]\n",
            " [10.]\n",
            " [ 9.]\n",
            " [ 6.]\n",
            " [10.]\n",
            " [12.]\n",
            " [ 8.]\n",
            " [11.]\n",
            " [ 8.]\n",
            " [ 8.]\n",
            " [ 9.]\n",
            " [ 7.]\n",
            " [ 9.]\n",
            " [12.]\n",
            " [ 6.]\n",
            " [ 9.]\n",
            " [ 8.]\n",
            " [13.]\n",
            " [11.]\n",
            " [ 9.]\n",
            " [ 9.]\n",
            " [ 9.]\n",
            " [ 7.]\n",
            " [ 6.]\n",
            " [14.]\n",
            " [ 8.]\n",
            " [ 5.]\n",
            " [ 6.]\n",
            " [ 7.]\n",
            " [ 5.]\n",
            " [ 7.]\n",
            " [11.]\n",
            " [ 8.]\n",
            " [ 8.]\n",
            " [12.]\n",
            " [ 7.]\n",
            " [15.]\n",
            " [10.]\n",
            " [ 8.]\n",
            " [16.]\n",
            " [10.]\n",
            " [19.]\n",
            " [ 7.]\n",
            " [ 8.]\n",
            " [ 9.]\n",
            " [ 9.]\n",
            " [12.]\n",
            " [11.]\n",
            " [ 9.]\n",
            " [ 9.]\n",
            " [ 9.]\n",
            " [13.]\n",
            " [ 6.]\n",
            " [12.]\n",
            " [ 6.]\n",
            " [10.]\n",
            " [ 8.]\n",
            " [ 7.]\n",
            " [ 7.]\n",
            " [10.]\n",
            " [ 9.]\n",
            " [ 5.]\n",
            " [ 5.]\n",
            " [12.]\n",
            " [ 9.]\n",
            " [ 7.]\n",
            " [ 9.]\n",
            " [ 8.]\n",
            " [12.]\n",
            " [ 9.]\n",
            " [10.]\n",
            " [10.]\n",
            " [10.]\n",
            " [17.]\n",
            " [14.]\n",
            " [ 6.]\n",
            " [11.]\n",
            " [15.]\n",
            " [12.]\n",
            " [11.]\n",
            " [ 8.]\n",
            " [10.]\n",
            " [11.]\n",
            " [ 7.]\n",
            " [ 9.]\n",
            " [10.]\n",
            " [ 6.]\n",
            " [ 7.]\n",
            " [ 7.]\n",
            " [11.]\n",
            " [14.]\n",
            " [14.]\n",
            " [13.]\n",
            " [25.]\n",
            " [ 5.]\n",
            " [11.]\n",
            " [ 9.]\n",
            " [11.]\n",
            " [ 8.]\n",
            " [12.]\n",
            " [ 5.]\n",
            " [ 8.]\n",
            " [ 9.]\n",
            " [10.]\n",
            " [ 8.]\n",
            " [10.]\n",
            " [ 9.]\n",
            " [ 7.]\n",
            " [ 6.]\n",
            " [10.]\n",
            " [ 5.]\n",
            " [13.]\n",
            " [ 8.]\n",
            " [10.]\n",
            " [ 8.]\n",
            " [10.]\n",
            " [ 6.]\n",
            " [ 8.]\n",
            " [ 5.]\n",
            " [17.]\n",
            " [16.]\n",
            " [11.]\n",
            " [ 6.]\n",
            " [17.]\n",
            " [ 6.]\n",
            " [ 8.]\n",
            " [ 8.]\n",
            " [ 9.]\n",
            " [ 9.]\n",
            " [ 9.]\n",
            " [ 9.]\n",
            " [11.]\n",
            " [ 9.]\n",
            " [13.]\n",
            " [12.]\n",
            " [ 9.]\n",
            " [ 9.]\n",
            " [11.]\n",
            " [11.]\n",
            " [10.]\n",
            " [10.]\n",
            " [13.]\n",
            " [11.]\n",
            " [ 7.]\n",
            " [ 6.]\n",
            " [ 8.]\n",
            " [10.]\n",
            " [ 6.]\n",
            " [11.]\n",
            " [ 9.]\n",
            " [11.]\n",
            " [ 4.]\n",
            " [13.]\n",
            " [12.]\n",
            " [23.]\n",
            " [ 9.]\n",
            " [ 7.]\n",
            " [ 9.]\n",
            " [10.]\n",
            " [ 6.]\n",
            " [ 9.]\n",
            " [ 9.]\n",
            " [ 7.]\n",
            " [ 5.]\n",
            " [ 9.]\n",
            " [10.]\n",
            " [10.]\n",
            " [11.]\n",
            " [12.]\n",
            " [ 9.]\n",
            " [ 9.]\n",
            " [10.]\n",
            " [ 6.]\n",
            " [ 9.]\n",
            " [ 9.]\n",
            " [14.]\n",
            " [ 9.]\n",
            " [10.]\n",
            " [ 8.]\n",
            " [ 4.]\n",
            " [10.]\n",
            " [ 9.]\n",
            " [ 5.]\n",
            " [ 9.]\n",
            " [10.]\n",
            " [10.]\n",
            " [ 7.]\n",
            " [11.]\n",
            " [ 9.]\n",
            " [11.]\n",
            " [10.]\n",
            " [ 4.]\n",
            " [ 8.]\n",
            " [10.]\n",
            " [ 7.]\n",
            " [10.]\n",
            " [ 9.]\n",
            " [ 9.]\n",
            " [13.]\n",
            " [ 9.]\n",
            " [10.]\n",
            " [ 5.]\n",
            " [ 9.]\n",
            " [10.]\n",
            " [ 9.]\n",
            " [ 8.]\n",
            " [ 4.]\n",
            " [10.]\n",
            " [ 7.]\n",
            " [17.]\n",
            " [16.]\n",
            " [ 9.]\n",
            " [ 6.]\n",
            " [ 9.]\n",
            " [ 7.]\n",
            " [ 3.]\n",
            " [10.]\n",
            " [10.]\n",
            " [10.]\n",
            " [ 9.]\n",
            " [10.]\n",
            " [10.]\n",
            " [10.]\n",
            " [11.]\n",
            " [ 9.]\n",
            " [ 7.]\n",
            " [ 4.]\n",
            " [10.]\n",
            " [10.]\n",
            " [10.]\n",
            " [ 6.]\n",
            " [ 9.]\n",
            " [15.]\n",
            " [ 9.]\n",
            " [10.]\n",
            " [ 9.]\n",
            " [ 8.]\n",
            " [11.]\n",
            " [15.]\n",
            " [10.]\n",
            " [10.]\n",
            " [ 6.]\n",
            " [10.]\n",
            " [10.]\n",
            " [ 5.]\n",
            " [ 7.]\n",
            " [13.]\n",
            " [10.]\n",
            " [ 4.]\n",
            " [ 8.]\n",
            " [11.]\n",
            " [ 4.]\n",
            " [11.]\n",
            " [ 4.]\n",
            " [ 6.]\n",
            " [ 7.]\n",
            " [ 8.]\n",
            " [ 8.]\n",
            " [15.]\n",
            " [ 9.]\n",
            " [11.]\n",
            " [ 6.]\n",
            " [ 9.]\n",
            " [20.]\n",
            " [ 8.]\n",
            " [ 9.]\n",
            " [11.]\n",
            " [12.]\n",
            " [ 9.]\n",
            " [ 9.]\n",
            " [14.]\n",
            " [ 8.]\n",
            " [17.]\n",
            " [ 6.]\n",
            " [10.]\n",
            " [ 9.]\n",
            " [12.]\n",
            " [11.]\n",
            " [11.]\n",
            " [ 8.]\n",
            " [ 9.]\n",
            " [10.]\n",
            " [ 9.]\n",
            " [ 8.]\n",
            " [21.]\n",
            " [16.]\n",
            " [ 9.]\n",
            " [11.]\n",
            " [ 9.]\n",
            " [11.]\n",
            " [ 9.]\n",
            " [ 9.]\n",
            " [ 8.]\n",
            " [ 9.]\n",
            " [ 8.]\n",
            " [12.]\n",
            " [10.]\n",
            " [ 7.]\n",
            " [11.]\n",
            " [14.]\n",
            " [ 8.]\n",
            " [10.]\n",
            " [ 7.]\n",
            " [20.]\n",
            " [24.]\n",
            " [16.]\n",
            " [11.]\n",
            " [17.]\n",
            " [ 9.]\n",
            " [ 7.]\n",
            " [ 8.]\n",
            " [ 9.]\n",
            " [11.]\n",
            " [ 6.]\n",
            " [10.]\n",
            " [ 9.]\n",
            " [13.]\n",
            " [ 8.]\n",
            " [ 6.]\n",
            " [ 9.]\n",
            " [18.]\n",
            " [10.]\n",
            " [ 6.]\n",
            " [ 8.]\n",
            " [14.]\n",
            " [ 6.]\n",
            " [ 7.]\n",
            " [ 8.]\n",
            " [14.]\n",
            " [ 9.]\n",
            " [18.]\n",
            " [12.]\n",
            " [20.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gDMcMvg0oB-"
      },
      "source": [
        "def get_train_data(mb_size, n):\n",
        "    if n == 0 :\n",
        "        np.random.shuffle(shuffle_map[:test_begin_index])\n",
        "\n",
        "    train_data = data[shuffle_map[mb_size * n : mb_size * (n+1)]]\n",
        "\n",
        "    return train_data[:, : -output_cnt], train_data[:, -output_cnt : ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fzEw6Py3WF5",
        "outputId": "4958eeee-f455-4539-8ab4-7743194d8ee3"
      },
      "source": [
        "train_x, train_y = get_train_data(mb_size = 2 , n = 0)\n",
        "print(train_x)\n",
        "print(\"========================\")\n",
        "print(train_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.     0.     0.     0.615  0.49   0.17   1.145  0.4915 0.208  0.343 ]\n",
            " [1.     0.     0.     0.61   0.48   0.15   1.1495 0.564  0.274  0.264 ]]\n",
            "========================\n",
            "[[13.]\n",
            " [ 8.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHHDCU9I2R3-"
      },
      "source": [
        "mb_size = 2\n",
        "\n",
        "train_data_mini_1 = data[shuffle_map[ 0 : 2 ]]\n",
        "train_data_mini_2 = data[shuffle_map[ 2 : 4 ]]\n",
        "train_data_mini_3 = data[shuffle_map[ 4 : 6 ]]\n",
        "train_data_mini_4 = data[shuffle_map[ 6 : 8 ]]\n",
        "\n",
        "train_data_mini_n = data[shuffle_map[ mb_size * 0 : mb_size * (0+1)]]\n",
        "train_data_mini_n = data[shuffle_map[ mb_size * 1 : mb_size * (1+1)]]\n",
        "train_data_mini_n = data[shuffle_map[ mb_size * 2 : mb_size * (2+1)]]\n",
        "train_data_mini_n = data[shuffle_map[ mb_size * 3 : mb_size * (3+1)]]\n",
        "\n",
        "#train_data_mini_n = data[shuffle_map[ mb_size * n : mb_size * (n+1)]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jT7gkmKK2ScZ",
        "outputId": "a6420c2c-70a0-4214-9e07-896b1b8d8979"
      },
      "source": [
        "def run_train(x, y):\n",
        "    loss = 0\n",
        "    accuracy = 100\n",
        "    return loss, accuracy\n",
        "\n",
        "run_train(0,0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2KuxEZR4yxp",
        "outputId": "4608ffe2-c1cc-480b-d46b-63b1e9c67fb7"
      },
      "source": [
        "def run_test(x, y):\n",
        "    accuracy = 95\n",
        "    return accuracy\n",
        "\n",
        "run_test(0,0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVE4QtjcxGzT"
      },
      "source": [
        "#### 07_23"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tr6W2f-u4zqH"
      },
      "source": [
        "def train_and_test(epoch_count, mb_size, report, train_ratio):\n",
        "    mini_batch_step_count = arrange_data(mb_size, train_ratio)\n",
        "\n",
        "    test_x, test_y = get_test_data()\n",
        "    losses_mean_row, accs_mean_row = [], []\n",
        "\n",
        "    for epoch in range(epoch_count):\n",
        "        losses = []\n",
        "        accs   = []\n",
        "        for n in range(mini_batch_step_count):\n",
        "            train_x ,train_y = get_train_data(mb_size, n)\n",
        "            loss, acc = run_train(train_x, train_y)\n",
        "            losses.append(loss)\n",
        "            accs.append(acc)\n",
        "        \n",
        "        if report > 0 and (epoch + 1) % report == 0:\n",
        "            acc = run_test(test_x, test_y)\n",
        "            print(\"Epoch {} : Train - Loss = {:.3f}, Accuracy = {:.3f} / Test - Accuracy = {:.3f}\".\\\n",
        "                  format(epoch + 1, np.mean(losses), np.mean(accs), acc))\n",
        "            \n",
        "        losses_mean = np.mean(losses)\n",
        "        accs_mean   = np.mean(accs) * 100\n",
        "\n",
        "        losses_mean_row.append(losses_mean)\n",
        "        accs_mean_row.append(accs_mean)\n",
        "\n",
        "    final_acc = run_test(test_x, test_y)\n",
        "    print(\"=\"*30, \"Final TEST\", \"=\"*30)\n",
        "    print(\"\\nFinal Accuracy : {}\".format(final_acc))\n",
        "\n",
        "    return losses_mean_row, accs_mean_row, final_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3oEKbdsnzsO",
        "outputId": "de5340dd-02a9-48d0-ccee-89ea4f9707c1"
      },
      "source": [
        "losses_mean_row, accs_mean_row, final_acc = train_and_test(epoch_count = 10,\n",
        "                                                           mb_size = 2, \n",
        "                                                           report = 1, \n",
        "                                                           train_ratio = 0.8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 : Train - Loss = 0.000, Accuracy = 100.000 / Test - Accuracy = 95.000\n",
            "Epoch 2 : Train - Loss = 0.000, Accuracy = 100.000 / Test - Accuracy = 95.000\n",
            "Epoch 3 : Train - Loss = 0.000, Accuracy = 100.000 / Test - Accuracy = 95.000\n",
            "Epoch 4 : Train - Loss = 0.000, Accuracy = 100.000 / Test - Accuracy = 95.000\n",
            "Epoch 5 : Train - Loss = 0.000, Accuracy = 100.000 / Test - Accuracy = 95.000\n",
            "Epoch 6 : Train - Loss = 0.000, Accuracy = 100.000 / Test - Accuracy = 95.000\n",
            "Epoch 7 : Train - Loss = 0.000, Accuracy = 100.000 / Test - Accuracy = 95.000\n",
            "Epoch 8 : Train - Loss = 0.000, Accuracy = 100.000 / Test - Accuracy = 95.000\n",
            "Epoch 9 : Train - Loss = 0.000, Accuracy = 100.000 / Test - Accuracy = 95.000\n",
            "Epoch 10 : Train - Loss = 0.000, Accuracy = 100.000 / Test - Accuracy = 95.000\n",
            "============================== Final TEST ==============================\n",
            "\n",
            "Final Accuracy : 95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ne_X9TCNyidp",
        "outputId": "d7c1968f-d126-42d1-b556-efe9364c9332"
      },
      "source": [
        "epoch_count = 10\n",
        "report      = 4\n",
        "\n",
        "for epoch in range(epoch_count):\n",
        "    print((epoch + 1) % report == 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "False\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IPfJBUTy1kE"
      },
      "source": [
        "def forward_neuralnet(x):\n",
        "    y_hat = np.matmul(x, weight) + bias \n",
        "    # x > backprop_neuralnet\n",
        "    return y_hat, x                     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ylj6xmLDzO-I",
        "outputId": "099dc5a1-2f38-4032-97e0-c7f2e2556903"
      },
      "source": [
        "y_hat, _ = forward_neuralnet(train_x)\n",
        "print(y_hat)\n",
        "print(y_hat.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.06386726]\n",
            " [-0.06625431]]\n",
            "(2, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecLYKbEkzUa8"
      },
      "source": [
        "def forward_postproc(y_hat, y):\n",
        "  diff = y_hat - y\n",
        "  square = np.square(diff)\n",
        "  loss = np.mean(square)\n",
        "  # diff > backprop_postproc\n",
        "  return loss, diff             "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsBSWw4Tz6Ww",
        "outputId": "64ec29fd-aa00-4680-e97c-a20ac69170a6"
      },
      "source": [
        "loss = forward_postproc(y_hat, train_y)\n",
        "print('MSE : ', loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE :  (117.86454321815947, array([[-13.06386726],\n",
            "       [ -8.06625431]]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpK5ZfdM0IWa"
      },
      "source": [
        "def eval_accuracy(y_hat, y):\n",
        "  # 오차율 mdiff , 하나의 값으로 만들기 위해 np.mean 사용\n",
        "  mdiff = np.mean(np.abs((y_hat - y) / y))  \n",
        "  return 1 - mdiff"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D34FSfeH0yhB",
        "outputId": "04778a11-5e50-4ff0-c475-b34d8a5cc96a"
      },
      "source": [
        "acc = eval_accuracy(y_hat, train_y)\n",
        "print('ACC : {:.3f}'.format(acc * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ACC : -0.660\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urZoQwmE1EB2"
      },
      "source": [
        "# backprop_nueralnet : 가중치, 편향 경사하강법 연산 (수업자료 참고)\n",
        "def backprop_nueralnet(G_output, x):\n",
        "  global weight, bias\n",
        "  x_transpose = x.transpose()\n",
        "  G_w = np.matmul(x_transpose, G_output)\n",
        "  G_b = np.sum(G_output, axis = 0)\n",
        "\n",
        "  weight -= LEARNING_RATE * G_w\n",
        "  bias   -= LEARNING_RATE * G_b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN4dCW8c3wao",
        "outputId": "0815d144-a99d-426a-8018-3d98f747ac3b"
      },
      "source": [
        "diff = y_hat - train_y\n",
        "square = np.square(diff)\n",
        "print('square : \\n', square)\n",
        "print('diff shape ; ', diff.shape)\n",
        "\n",
        "row_count_M = diff.shape[0]\n",
        "col_count_N = diff.shape[1]\n",
        "print('row_count_M : ', row_count_M)\n",
        "print('col_count_N : ', col_count_N)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "square : \n",
            " [[170.66462778]\n",
            " [ 65.06445866]]\n",
            "diff shape ;  (2, 1)\n",
            "row_count_M :  2\n",
            "col_count_N :  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJZHcR86-74K",
        "outputId": "c98f9bbe-29e6-4655-b34b-0708b60ce9e2"
      },
      "source": [
        "mse = (square[0][0] + square[1][0]) / (row_count_M + col_count_N)\n",
        "print('MSE : ', mse)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE :  78.57636214543965\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gW1trdxh_mui"
      },
      "source": [
        "def backprop_postproc(diff):\n",
        "  M_N = diff.shape\n",
        "  g_mse_square = np.ones(M_N) / np.prod(M_N)\n",
        "  g_square_diff = 2 * diff\n",
        "  g_diff_output = 1\n",
        "\n",
        "  G_diff = g_mse_square * g_square_diff\n",
        "  G_output = g_diff_output * G_diff\n",
        "\n",
        "  return G_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKkXbU2oAPqK"
      },
      "source": [
        "def run_train(x, y):\n",
        "  # 순전파\n",
        "  y_hat, aux_nn_x = forward_neuralnet(x)\n",
        "  loss, aux_pp_diff = forward_postproc(y_hat, y)\n",
        "\n",
        "  accuracy = eval_accuracy(y_hat, y)\n",
        "  \n",
        "  # 역전파\n",
        "  G_output = backprop_postproc(aux_pp_diff)\n",
        "  backprop_nueralnet(G_output, aux_nn_x)\n",
        "\n",
        "  return loss, accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FegDSQ15CgIh"
      },
      "source": [
        "def run_test(x, y):\n",
        "  y_hat, _ = forward_neuralnet(x)\n",
        "  accuracy = eval_accuracy(y_hat, y)\n",
        "\n",
        "  return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sol-I68RC2ez",
        "outputId": "a97b0335-7cbc-4303-9023-b7e4afd2c8d9"
      },
      "source": [
        "weight_initial, bias_initial, losses_mean_row, accs_mean_row, final_acc = main_execute(epoch_count = 1000, mb_size = 36, report = 50, train_ratio = 0.8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial Weight Value : \n",
            "[[-0.03867246]\n",
            " [-0.04705227]\n",
            " [ 0.00877279]\n",
            " [-0.01016111]\n",
            " [ 0.02459196]\n",
            " [ 0.05817322]\n",
            " [ 0.03484871]\n",
            " [ 0.02605906]\n",
            " [-0.00691521]\n",
            " [ 0.00746208]] \n",
            "Initial Bias Value : \n",
            "[0.] \n",
            "Epoch 50 : Train - Loss = 4.835, Accuracy = 0.838 / Test - Accuracy = 0.848\n",
            "Epoch 100 : Train - Loss = 4.796, Accuracy = 0.839 / Test - Accuracy = 0.840\n",
            "Epoch 150 : Train - Loss = 4.780, Accuracy = 0.839 / Test - Accuracy = 0.829\n",
            "Epoch 200 : Train - Loss = 4.778, Accuracy = 0.839 / Test - Accuracy = 0.841\n",
            "Epoch 250 : Train - Loss = 4.777, Accuracy = 0.839 / Test - Accuracy = 0.837\n",
            "Epoch 300 : Train - Loss = 4.760, Accuracy = 0.839 / Test - Accuracy = 0.848\n",
            "Epoch 350 : Train - Loss = 4.762, Accuracy = 0.839 / Test - Accuracy = 0.844\n",
            "Epoch 400 : Train - Loss = 4.778, Accuracy = 0.840 / Test - Accuracy = 0.837\n",
            "Epoch 450 : Train - Loss = 4.773, Accuracy = 0.840 / Test - Accuracy = 0.835\n",
            "Epoch 500 : Train - Loss = 4.784, Accuracy = 0.839 / Test - Accuracy = 0.848\n",
            "Epoch 550 : Train - Loss = 4.762, Accuracy = 0.840 / Test - Accuracy = 0.843\n",
            "Epoch 600 : Train - Loss = 4.760, Accuracy = 0.840 / Test - Accuracy = 0.844\n",
            "Epoch 650 : Train - Loss = 4.754, Accuracy = 0.841 / Test - Accuracy = 0.838\n",
            "Epoch 700 : Train - Loss = 4.770, Accuracy = 0.840 / Test - Accuracy = 0.815\n",
            "Epoch 750 : Train - Loss = 4.774, Accuracy = 0.839 / Test - Accuracy = 0.842\n",
            "Epoch 800 : Train - Loss = 4.781, Accuracy = 0.839 / Test - Accuracy = 0.846\n",
            "Epoch 850 : Train - Loss = 4.767, Accuracy = 0.839 / Test - Accuracy = 0.842\n",
            "Epoch 900 : Train - Loss = 4.760, Accuracy = 0.840 / Test - Accuracy = 0.840\n",
            "Epoch 950 : Train - Loss = 4.752, Accuracy = 0.840 / Test - Accuracy = 0.838\n",
            "Epoch 1000 : Train - Loss = 4.757, Accuracy = 0.840 / Test - Accuracy = 0.843\n",
            "============================== Final TEST ==============================\n",
            "\n",
            "Final Accuracy : 0.8431010064806703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GNqDMbalAy8"
      },
      "source": [
        "#### 0727 + 저번시간복습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BOW0lv2RSxC",
        "outputId": "229c8f74-5d2b-4b3e-bf13-d7c9c397c11e"
      },
      "source": [
        "print('weight : \\n', weight)\n",
        "print('bias : \\n', bias)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weight : \n",
            " [[  1.29792306]\n",
            " [  1.04462238]\n",
            " [  0.38715993]\n",
            " [  0.02335522]\n",
            " [ 10.45666974]\n",
            " [  9.72304926]\n",
            " [  8.1872382 ]\n",
            " [-19.18394693]\n",
            " [ -9.25774857]\n",
            " [  9.44206416]]\n",
            "bias : \n",
            " [2.8066573]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84S-S999ijlC",
        "outputId": "a63a4d45-913b-4107-b56e-4cb87d463977"
      },
      "source": [
        "new_x = [0, 1, 0, 0.685,0.545, 0.18,1.42,0.674,0.392,0.5]\n",
        "\n",
        "pred_Y, _ = forward_neuralnet(new_x)\n",
        "print('pred_Y : ', pred_Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pred_Y :  [11.10420454]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdNcQIETjqjL"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "U3Y7uDPKjiwM",
        "outputId": "e8746ad2-048b-4710-ba2b-856c3ada1d04"
      },
      "source": [
        "# 시각화\n",
        "plt.plot(losses_mean_row, '--o', color='purple', label='Loss')\n",
        "plt.plot(accs_mean_row, '--o', color='yellow', label='Acc')\n",
        "\n",
        "plt.title('Single layer Perceptron Model - ACC : {:.3f}'.\\\n",
        "          format(final_acc * 100))\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Indicators')\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}